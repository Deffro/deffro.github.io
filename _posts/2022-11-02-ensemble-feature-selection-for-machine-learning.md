---
title: "Ensemble Feature Selection for Machine Learning"
date: 2022-11-02
author_profile: true
excerpt: "Investigate if ensemble feature selection methods are superior of individual in machine learning classification problems."
tags: [features, machine learning,]
header:
  image: "images/projects/ensemble-fs.jpg"
  teaser: "images/teasers/ensemble-fs.jpg"
categories:
  - Machine Learning
  - Feature Selection
mathjax: "true"
---

**The project is available online on [Towards Data Science](https://towardsdatascience.com/ensemble-feature-selection-for-machine-learning-c0df77b970f9)**.

Most of the content of this article is from my paper entitled:
“An Evaluation of Feature Selection Methods for Environmental Data”, and is available [here](https://www.sciencedirect.com/science/article/abs/pii/S1574954121000157) for anyone interested.

In my previous [article](https://towardsdatascience.com/feature-selection-for-machine-learning-3-categories-and-12-methods-6a4403f86543), I presented 12 individual feature selection methods. This article serves as the next step to feature selection.

If you are here, I suppose you are already familiar with the well-established ensemble on classification algorithms, which provides better results and robustness than employing single algorithms. The same principle can be applied to feature selection algorithms.

## Ensemble Feature Selection
The idea behind ensemble feature selection is to combine multiple different feature selection methods, taking into account their strengths, and create an optimal best subset.
In general, it makes a better feature space and reduces the risk of choosing an unstable subset.
Besides, a single method may result in a subset that can be considered a local optimum, while an ensemble might provide more stable results.

Continue your read on [Towards Data Science](https://towardsdatascience.com/ensemble-feature-selection-for-machine-learning-c0df77b970f9).